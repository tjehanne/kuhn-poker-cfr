"""
Script principal pour entra√Æner et analyser l'agent de Poker CFR
D√©montre l'apprentissage et l'analyse de la strat√©gie Nash Equilibrium
"""

import numpy as np
import matplotlib.pyplot as plt
from cfr_algorithm import CFRTrainer
from cfr_academic import compute_exploitability, verify_nash_value, compute_game_value
from kuhn_poker import KuhnPoker
import time


def analyze_exploitability_academic(trainer: CFRTrainer) -> float:
    """
    Calcule l'exploitabilit√© selon la m√©trique acad√©mique standard
    (Best Response Value - Standard Libratus/Pluribus/OpenSpiel)
    
    Args:
        trainer: L'entra√Æneur CFR avec la strat√©gie apprise
        
    Returns:
        Valeur d'exploitabilit√© (en milli-big-blinds)
    """
    strategy_profile = trainer.get_strategy_profile()
    return compute_exploitability(trainer.game, strategy_profile)


def analyze_exploitability(trainer: CFRTrainer, use_best_response: bool = True) -> float:
    """
    Calcule l'exploitabilit√© avec choix de m√©trique
    
    Args:
        trainer: L'entra√Æneur CFR avec la strat√©gie apprise
        use_best_response: Si True, utilise best response value (standard acad√©mique)
                          Si False, utilise distance euclidienne (m√©trique simplifi√©e)
        
    Returns:
        Valeur d'exploitabilit√© (en milli-big-blinds)
    """
    if use_best_response:
        # M√©thode acad√©mique standard (Libratus/Pluribus)
        return analyze_exploitability_academic(trainer)
    else:
        # M√©thode alternative: distance euclidienne pond√©r√©e
        strategy_profile = trainer.get_strategy_profile()
        
        nash_strategies = {
            '0': np.array([2/3, 1/3]),      '0pb': np.array([1.0, 0.0]),
            '1': np.array([1.0, 0.0]),      '1pb': np.array([1.0, 0.0]),
            '2': np.array([0.0, 1.0]),      '2pb': np.array([0.0, 1.0]),
            '0p': np.array([0.0, 1.0]),     '0b': np.array([1.0, 0.0]),
            '1p': np.array([1.0, 0.0]),     '1b': np.array([2/3, 1/3]),
            '2p': np.array([1.0, 0.0]),     '2b': np.array([0.0, 1.0]),
        }
        
        visit_frequencies = {
            '0': 1/3,  '0p': 1/6,  '0b': 1/6,  '0pb': 1/18,
            '1': 1/3,  '1p': 1/6,  '1b': 1/6,  '1pb': 1/18,
            '2': 1/3,  '2p': 1/6,  '2b': 1/6,  '2pb': 0.0,
        }
        
        total_weighted_distance = 0.0
        total_weight = 0.0
        
        for infoset_key, nash_strategy in nash_strategies.items():
            if infoset_key in strategy_profile:
                learned_strategy = strategy_profile[infoset_key]
                distance = np.sqrt(np.sum((learned_strategy - nash_strategy) ** 2))
                weight = visit_frequencies.get(infoset_key, 1.0)
                total_weighted_distance += distance * weight
                total_weight += weight
        
        avg_distance = (total_weighted_distance / total_weight) if total_weight > 0 else 0
        return avg_distance * 1000


def run_training_experiment(iterations: int = 10000):
    """
    Ex√©cute une exp√©rience d'entra√Ænement compl√®te avec analyse
    
    Args:
        iterations: Nombre d'it√©rations d'entra√Ænement
    """
    print("\n" + "="*70)
    print("POKER AI - COUNTERFACTUAL REGRET MINIMIZATION (CFR)")
    print("="*70)
    print(f"\nJeu: Kuhn Poker")
    print(f"Algorithme: CFR (Counterfactual Regret Minimization)")
    print(f"It√©rations: {iterations:,}")
    print("\nD√©but de l'entra√Ænement...")
    
    start_time = time.time()
    
    # Cr√©er et entra√Æner l'agent
    trainer = CFRTrainer()
    trainer.train(iterations)
    
    training_time = time.time() - start_time
    
    print(f"\nEntra√Ænement termin√© en {training_time:.2f} secondes")
    print(f"Vitesse: {iterations/training_time:.0f} it√©rations/seconde")
    
    # Afficher la strat√©gie apprise
    trainer.display_strategy()
    
    # Analyser les strat√©gies par comparaison directe avec Nash th√©orique
    strategy_profile = trainer.get_strategy_profile()
    
    # Extraire les strat√©gies cl√©s
    jack_bet = strategy_profile.get('0', np.array([0.5, 0.5]))[1] * 100
    queen_call = strategy_profile.get('1b', np.array([0.5, 0.5]))[1] * 100
    king_bet = strategy_profile.get('2', np.array([0.5, 0.5]))[1] * 100
    
    # Calculer la pr√©cision (erreur relative)
    jack_error = abs(jack_bet - 33.3) / 33.3 * 100
    queen_error = abs(queen_call - 33.3) / 33.3 * 100
    king_error = abs(king_bet - 100.0) / 100.0 * 100
    avg_error = (jack_error + queen_error + king_error) / 3
    overall_accuracy = max(0, 100 - avg_error)
    
    # Calculer la game value
    game_value = compute_game_value(trainer.game, strategy_profile)
    nash_value = -1/18  # Valeur th√©orique de Nash pour Kuhn Poker (convention acad√©mique)
    
    print(f"\n" + "="*70)
    print("ANALYSE DE LA STRAT√âGIE")
    print("="*70)
    
    print(f"\nüìä Game Value:")
    print(f"   Valeur apprise:    {game_value:.6f}")
    print(f"   Valeur Nash:       {nash_value:.6f} (-1/18)")
    print(f"   Diff√©rence:        {abs(game_value - nash_value):.6f}")
    
    print(f"\nüìä Pr√©cision des strat√©gies vs Nash th√©orique:")
    print(f"   Jack bluff:      {jack_bet:5.1f}% (th√©orie: 33.3%) ‚Üí erreur {jack_error:.1f}%")
    print(f"   Queen call:      {queen_call:5.1f}% (th√©orie: 33.3%) ‚Üí erreur {queen_error:.1f}%")  
    print(f"   King value bet:  {king_bet:5.1f}% (th√©orie: 100%)  ‚Üí erreur {king_error:.1f}%")
    print(f"\n   üìà Pr√©cision globale: {overall_accuracy:.1f}%")
    
    if overall_accuracy >= 99.5:
        quality_emoji = "‚ú®"
        quality = "EXCELLENT - Convergence quasi-parfaite vers Nash"
    elif overall_accuracy >= 99.0:
        quality_emoji = "‚≠ê"
        quality = "TR√àS BON - Convergence solide vers Nash"
    elif overall_accuracy >= 95.0:
        quality_emoji = "üëç"
        quality = "BON - Convergence satisfaisante"
    else:
        quality_emoji = "‚ö†Ô∏è"
        quality = "MOYEN - N√©cessite plus d'it√©rations"
    
    print(f"\n{quality_emoji} Qualit√©: {quality}")
    
    # Afficher des statistiques sur les information sets
    strategy_profile = trainer.get_strategy_profile()
    print(f"\nNombre d'information sets explor√©s: {len(strategy_profile)}")
    
    return trainer


def compare_strategies(trainer: CFRTrainer):
    """
    Compare les strat√©gies pour diff√©rentes cartes
    
    Args:
        trainer: L'entra√Æneur CFR avec la strat√©gie apprise
    """
    print("\n" + "="*60)
    print("ANALYSE COMPARATIVE DES STRAT√âGIES")
    print("="*60)
    
    strategy_profile = trainer.get_strategy_profile()
    game = KuhnPoker()
    
    # Analyser les d√©cisions au premier coup
    print("\nD√©cisions initiales (premier coup):")
    print("-" * 40)
    
    for card in range(3):
        infoset_key = f"{card}"
        if infoset_key in strategy_profile:
            strategy = strategy_profile[infoset_key]
            card_name = game.get_card_name(card)
            print(f"{card_name:6s}: Pass={strategy[0]*100:5.1f}%, Bet={strategy[1]*100:5.1f}%")
    
    # Analyser les r√©ponses apr√®s un bet
    print("\nR√©ponses apr√®s un BET adverse:")
    print("-" * 40)
    
    for card in range(3):
        infoset_key = f"{card}b"
        if infoset_key in strategy_profile:
            strategy = strategy_profile[infoset_key]
            card_name = game.get_card_name(card)
            print(f"{card_name:6s}: Pass={strategy[0]*100:5.1f}% (fold), "
                  f"Bet={strategy[1]*100:5.1f}% (call)")


def explain_nash_equilibrium():
    """
    Explique l'√©quilibre de Nash dans Kuhn Poker
    """
    print("\n" + "="*70)
    print("√âQUILIBRE DE NASH TH√âORIQUE - KUHN POKER")
    print("="*70)
    print("""
L'√©quilibre de Nash dans Kuhn Poker (solution th√©orique optimale):

JOUEUR avec JACK (carte la plus faible):
  - Au d√©but: PASS 2/3, BET 1/3 (bluffer 33%% du temps au premier coup)
  - Apr√®s pass/bet: Toujours FOLD (ne jamais call avec Jack)
  
JOUEUR avec QUEEN (carte moyenne):
  - Au d√©but: Toujours PASS
  - Apr√®s pass/bet: Toujours FOLD (ne pas call avec Queen)
  
JOUEUR avec KING (carte la plus forte):
  - Au d√©but: BET 3 fois sur 3 (toujours bet pour value)
  - Apr√®s pass/bet: Toujours CALL/BET

PROPRI√âT√âS:
  - Valeur du jeu: -1/18 ‚âà -0.0556 pour le joueur 0
  - Aucun joueur ne peut am√©liorer son gain en changeant unilat√©ralement
  - La strat√©gie est √©quilibr√©e entre bluffs et value bets
  
POURQUOI C'EST OPTIMAL:
  - Jack bluffe 1/3 du temps pour emp√™cher l'adversaire de toujours folder
  - King mise toujours pour value avec la meilleure carte
  - Queen fold car elle perd contre King et peut √™tre bluff√©e par Jack
  - Le bluff √† 33%% rend l'adversaire indiff√©rent entre call et fold
    """)


def visualize_convergence(max_iterations: int = 100000, checkpoints: int = 20):
    """
    Visualise la convergence de l'algorithme CFR avec tracking temps r√©el
    Similaire √† l'approche de Libratus/Pluribus
    
    Args:
        max_iterations: Nombre total d'it√©rations
        checkpoints: Nombre de points de v√©rification
    """
    print("\n" + "="*70)
    print("ANALYSE DE CONVERGENCE (Tracking style Libratus)")
    print("="*70)
    print(f"Entra√Ænement avec {max_iterations:,} it√©rations...")
    print(f"M√©trique: Best Response Exploitability (standard acad√©mique)\n")
    
    checkpoint_interval = max_iterations // checkpoints
    exploitabilities = []
    strategy_accuracies = []
    iteration_counts = []
    
    trainer = CFRTrainer()
    
    for i in range(1, checkpoints + 1):
        # Entra√Æner
        trainer.train(checkpoint_interval, track_convergence=False)
        
        # Calculer exploitabilit√© (best response)
        exploit = analyze_exploitability(trainer, use_best_response=True)
        exploitabilities.append(exploit)
        
        # Calculer pr√©cision des strat√©gies cl√©s vs Nash (erreur relative)
        strategy_profile = trainer.get_strategy_profile()
        jack_bet = strategy_profile.get('0', np.array([0.5, 0.5]))[1] * 100
        queen_call = strategy_profile.get('1b', np.array([0.5, 0.5]))[1] * 100
        king_bet = strategy_profile.get('2', np.array([0.5, 0.5]))[1] * 100
        
        # Pr√©cision vs th√©orie (33.3%, 33.3%, 100%)
        jack_error = abs(jack_bet - 33.3) / 33.3 * 100
        queen_error = abs(queen_call - 33.3) / 33.3 * 100
        king_error = abs(king_bet - 100.0) / 100.0 * 100
        avg_error = (jack_error + queen_error + king_error) / 3
        overall_acc = max(0, 100 - avg_error)
        strategy_accuracies.append(overall_acc)
        
        iteration_counts.append(i * checkpoint_interval)
        
        if i % 5 == 0:
            print(f"  [{i * checkpoint_interval:>7,} iter] "
                  f"Exploit={exploit:>6.3f} mbb  |  "
                  f"Pr√©cision={overall_acc:>5.1f}%")
    
    # Cr√©er deux subplots
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
    
    # Graphique 1: Exploitabilit√© (Best Response)
    ax1.plot(iteration_counts, exploitabilities, 'b-', linewidth=2, marker='o', label='Exploitabilit√©')
    ax1.axhline(y=1.0, color='r', linestyle='--', alpha=0.7, linewidth=1.5, label='Seuil quasi-optimal (<1 mbb)')
    ax1.axhline(y=5.0, color='orange', linestyle='--', alpha=0.5, linewidth=1, label='Seuil expert (<5 mbb)')
    ax1.set_xlabel('Nombre d\'it√©rations', fontsize=12, fontweight='bold')
    ax1.set_ylabel('Exploitabilit√© (milli-big-blinds)', fontsize=12, fontweight='bold')
    ax1.set_title('Convergence CFR - Best Response Exploitability (Standard Acad√©mique)', 
                  fontsize=13, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    ax1.legend(loc='upper right')
    ax1.set_ylim(bottom=0)
    
    # Graphique 2: Pr√©cision des strat√©gies cl√©s
    ax2.plot(iteration_counts, strategy_accuracies, 'g-', linewidth=2, marker='s', label='Pr√©cision strat√©gies cl√©s')
    ax2.axhline(y=100, color='r', linestyle='--', alpha=0.7, linewidth=2, label='Nash parfait (100%)')
    ax2.axhline(y=99, color='orange', linestyle='--', alpha=0.5, linewidth=1, label='Seuil excellent (99%)')
    ax2.set_xlabel('Nombre d\'it√©rations', fontsize=12, fontweight='bold')
    ax2.set_ylabel('Pr√©cision (%)', fontsize=12, fontweight='bold')
    ax2.set_title('Convergence des strat√©gies cl√©s vers Nash (Jack bluff, Queen call, King bet)', 
                  fontsize=13, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    ax2.legend(loc='lower right')
    ax2.set_ylim(90, 100.5)
    
    plt.tight_layout()
    
    # Sauvegarder le graphique
    plt.savefig('d:\\Documents\\Ecole\\EPF\\5A EPF\\IA 2\\Poker\\cfr_convergence.png', 
                dpi=150, bbox_inches='tight')
    print(f"\nüìä Graphiques sauvegard√©s: cfr_convergence.png")
    print(f"   ‚Ä¢ Exploitabilit√© (Best Response Value)")
    print(f"   ‚Ä¢ Pr√©cision des strat√©gies cl√©s vs Nash")
    plt.close()
    
    return trainer


def choose_iterations() -> int:
    """
    Menu pour choisir le nombre d'it√©rations d'entra√Ænement
    
    Returns:
        Nombre d'it√©rations choisi
    """
    print("\n" + "="*70)
    print("CHOIX DU NOMBRE D'IT√âRATIONS")
    print("="*70)
    print("\nOptions disponibles:")
    print("  1. Rapide       - 10,000 it√©rations   (~0.5 sec)")
    print("  2. Normal       - 50,000 it√©rations   (~2.5 sec)")
    print("  3. √âlev√©        - 100,000 it√©rations  (~5 sec)")
    print("  4. Tr√®s √©lev√©   - 500,000 it√©rations  (~25 sec)")
    print("  5. Maximum      - 1,000,000 it√©rations (~50 sec)")
    print("  6. Personnalis√© - Entrer un nombre")
    
    while True:
        choice = input("\nVotre choix (1-6): ").strip()
        
        if choice == '1':
            return 10000
        elif choice == '2':
            return 50000
        elif choice == '3':
            return 100000
        elif choice == '4':
            return 500000
        elif choice == '5':
            return 1000000
        elif choice == '6':
            while True:
                try:
                    custom = int(input("Nombre d'it√©rations (min 1000): "))
                    if custom >= 1000:
                        return custom
                    else:
                        print("Minimum 1000 it√©rations requis.")
                except ValueError:
                    print("Veuillez entrer un nombre valide.")
        else:
            print("Choix invalide. Veuillez choisir entre 1 et 6.")


def main():
    """Fonction principale"""
    
    # Expliquer l'√©quilibre de Nash th√©orique
    explain_nash_equilibrium()
    
    # Choisir le nombre d'it√©rations
    iterations = choose_iterations()
    
    # Entra√Æner l'agent
    print("\n" + "="*70)
    print("PHASE 1: ENTRA√éNEMENT")
    print("="*70)
    trainer = run_training_experiment(iterations=iterations)
    
    # Comparer les strat√©gies
    compare_strategies(trainer)
    
    # Visualiser la convergence (optionnel - comment√© par d√©faut car prend du temps)
    print("\n" + "="*70)
    print("PHASE 2: ANALYSE DE CONVERGENCE (optionnel)")
    print("="*70)
    response = input("\nVoulez-vous analyser la convergence? (o/n): ").lower()
    
    if response == 'o':
        final_trainer = visualize_convergence(max_iterations=100000, checkpoints=20)
        print("\nStrat√©gie finale apr√®s convergence compl√®te:")
        final_trainer.display_strategy()
    
    print("\n" + "="*70)
    print("ENTRA√éNEMENT TERMIN√â")
    print("="*70)
    print("""
R√âSUM√â:
‚úì Algorithme CFR impl√©ment√© et test√©
‚úì Convergence vers l'√©quilibre de Nash d√©montr√©e
‚úì Strat√©gie analys√©e et compar√©e √† la th√©orie
    """)


if __name__ == "__main__":
    main()
